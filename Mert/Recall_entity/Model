import torch
from transformers import BertModel, BertTokenizer
from torch import nn

model_name = 'bert-base-uncased'

class TripletLoss(nn.Module):
    def __init__(self,margin=0):
        super(TripletLoss,self).__init__()
        self.margin=margin
    def forward(self,input,label,id):
        label=torch.tensor(label)
        input = torch.tensor(input)
        size_row=label.shape[0]
        x=input.repeat(size_row,1)
        num=x.mul(label)
        num=num.sum(1)
        x_norm=torch.norm(x,2,1)
        label_norm=torch.norm(label,2,1)
        norm=torch.mul(x_norm,label_norm)
        cos_loss=num/norm
        postive=cos_loss[id]
        cos_loss[id]=2.
        negative=torch.min(cos_loss)
        if negative-postive>0:
            return negative-postive
        else:
            return 0

class Model_recall_entity(nn.Module):
    def __init__(self):
        super().__init__()
        self.tokenizer = BertTokenizer.from_pretrained(model_name)
        self.model = BertModel.from_pretrained(model_name)
    def forward(self,input):
        input = self.tokenizer.encode(input, add_special_tokens=True)
        input = torch.tensor([input])
        return self.model(input)[0][0][0] 



